{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depression Tracker\n",
    "\n",
    "\n",
    "### Hidden Markov Model\n",
    "\n",
    "***Rabindra Nepal***\n",
    "\n",
    "Here, we implement the hidden Markov model algorithms and use them design an app - Depression Tracker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import math\n",
    "import random \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that you are developing a mobile application called “Depression Tracker” to\n",
    "detect depression tendency in people. This app will be installed in the user’s smartphone\n",
    "and will try to determine whether the behavior of the user demonstrates a pattern of\n",
    "depression. A person with depression tendency is assumed to show depressive behavior\n",
    "more often than an otherwise healthy person. The app will collect data on user’s observed\n",
    "actions and based on that will discover the user’s depression tendency that is hidden (or\n",
    "not directly observable). The app is non-intrusive and will collect data about the user’s\n",
    "actions passively (without requiring intervention).\n",
    "\n",
    "For designing this app, you have created a simple model that uses a set of behavioral\n",
    "identifiers or actions for discovering depression tendency. These actions are detectable or\n",
    "measurable by the smartphone. The actions are: physical movement, passive social\n",
    "networking (user doesn’t post any text/image, etc.), active social networking (user posts\n",
    "text/image, etc.), texting (either via social networking apps or cell phone provider’s\n",
    "texting service), and access apps/websites for psychological help or improvement.\n",
    "For this assignment, assume that every individual user’s mind can be in one of the two\n",
    "hidden states: healthy and depressed. The app intends to deduce these hidden states from\n",
    "five actions: movement, passive social networking, active social networking, texting, and\n",
    "accessing psychological apps/sites.\n",
    "\n",
    "You conducted a controlled experiment on a group of users to determine the observation\n",
    "or emission probabilities of the actions given the two hidden mental states (healthy and\n",
    "depressed).\n",
    "\n",
    "The observations derived from the experiment are summerized below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given information\n",
    "\n",
    "Creating different matrice/states from the given informations:\n",
    "\n",
    "#### Observable state codes (O): \n",
    "\n",
    "| Observable State | State Code | \n",
    "| --- | --- |\n",
    "| Movement | 0 |\n",
    "| Passive Social Networking | 1 |\n",
    "| Active Social Networking | 2 |\n",
    "| Texting | 3 |\n",
    "| Access Psych Health App/Sites| 4 |\n",
    "\n",
    "#### Hidden mental states (S):\n",
    "\n",
    "|Mental States|\n",
    "| --- |\n",
    "|healthy|\n",
    "|depressed|\n",
    "\n",
    "#### Observation probability table (B): \n",
    "\n",
    "B = [$b_j(m)$] , where $b_j(m)$ $\\equiv$ P($O_t=v_m | q_t = S_j$)\n",
    "\n",
    "|   -  | Movement (0) | Passive Social Networking (1) | Active Social Networking (2) | Texting (3) | Access Psych Health App/Sites (4)|\n",
    "| --- | --- | --- | --- | --- | -- | \n",
    "| depressed | 0.05 | 0.35 | 0.20 | 0.20 | 0.20 |\n",
    "| healthy | 0.50 | 0.10 | 0.30 | 0.10 | 0.0 |\n",
    "\n",
    "#### Initial state probability ($\\Pi$):\n",
    "\n",
    "$\\Pi = [\\pi_i]$ where $\\pi_i \\equiv P(q_1 = S_i)$\n",
    "\n",
    "$\\Pi = [\\pi_{depressed} = 0.50, \\pi_{healthy} = 0.50]$\n",
    "\n",
    "#### Transition probability (A):\n",
    "\n",
    "A = $[a_{ij}]$ where $a_{ij} \\equiv$ P($q_{t+1} = S_j | q_t = S_i$) \n",
    "\n",
    "P($q_{t+1} = healthy | q_t = healthy$) = 0.80 $\\Rightarrow$ P($q_{t+1} = depressed | q_t = healthy$) = 0.20\n",
    "\n",
    "P($q_{t+1} = depressed | q_t = depressed$) = 0.999 $\\Rightarrow$ P($q_{t+1} = healthy | q_t = depressed$) = 0.001\n",
    "\n",
    "\n",
    "|  [t $\\downarrow$]  [(t+1) $\\rightarrow$]  | healthy | depressed |\n",
    "| --- | --- | -- |\n",
    "|healthy| 0.80 | 0.20 |\n",
    "|depressed | 0.001 | 0.999 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Model\n",
    "\n",
    "First, let us implement the data structures required to implement the HMM. The data structures are implemented as python class object in order to make it general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PI:\n",
    "    '''inital proabability matrix'''\n",
    "    def __init__(self, states_dict=None, initial_proba=None):\n",
    "        if states_dict is not None:\n",
    "            self.states_dict = states_dict\n",
    "        else:\n",
    "            self.states_dict = {'depressed': 0, 'healthy': 1}\n",
    "        \n",
    "        if initial_proba is not None:\n",
    "            self.initial_proba = initial_proba\n",
    "        else:\n",
    "            self.initial_proba = np.array([0.5, 0.5]) # default case\n",
    "    \n",
    "    @property\n",
    "    def vector(self):\n",
    "        return self.initial_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    '''transition probability matrix\n",
    "       n_states = number of hidden states\n",
    "       n_observations = number of possible observations\n",
    "    '''\n",
    "    def __init__(self, n_states=None, transition_matrix=None):\n",
    "        if n_states is not None:\n",
    "            self.n_states = n_states\n",
    "        else:\n",
    "            self.n_states = 2\n",
    "            \n",
    "        if transition_matrix is not None:\n",
    "            self.transition_matrix = transition_matrix\n",
    "        else:\n",
    "            self.transition_matrix = np.array([[0.80, 0.20], [0.001,  0.999]]) # default case\n",
    "            \n",
    "    @property\n",
    "    def matrix(self):\n",
    "        '''transition matrix'''\n",
    "        if self.transition_matrix.shape != (self.n_states, self.n_states):\n",
    "            raise ValueError('transition matrix should be of size: ', (self.n_states, self.n_states))\n",
    "        return self.transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B:\n",
    "    '''emission/observables proabability matrix'''\n",
    "    def __init__(self, emission_matrix=None):\n",
    "        if emission_matrix is not None:\n",
    "            self.emission_matrix = emission_matrix\n",
    "        else:\n",
    "            self.emission_matrix = np.array([[0.05, 0.35, 0.20, 0.20, 0.20], [0.50, 0.10, 0.30, 0.10, 0.0]]) # default case\n",
    "    \n",
    "    @property\n",
    "    def matrix(self):\n",
    "        return self.emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Observables:\n",
    "    '''returns a observation vector'''\n",
    "    def __init__(self, n_observations, observables_dict = None, observation_vector=None):\n",
    "        self.n_observations = n_observations\n",
    "        \n",
    "        if observables_dict is not None:\n",
    "            self.observables = observables_dict\n",
    "        else:\n",
    "            self.observables = {'Movement': 0, 'Passive Social Networking': 1, 'Active Social Networking': 2, \n",
    "                                'Texting': 3, 'Access Psych Health App/Sites': 4} # default case\n",
    "            \n",
    "        if observation_vector is not None:\n",
    "            assert len(observation_vector) == self.n_observations\n",
    "            self.observation_vector = observation_vector\n",
    "            \n",
    "        # if not passed: create a random observation vector\n",
    "        else:\n",
    "            observed_state = np.zeros(self.n_observations).astype('int32')\n",
    "            obs_values = list(self.observables.values())\n",
    "            for i in range(self.n_observations):\n",
    "                observed_state[i] = random.randint(min(obs_values), max(obs_values))\n",
    "            self.observation_vector = observed_state\n",
    "        \n",
    "    @property\n",
    "    def vector(self, observed_state=None):\n",
    "        '''return observables vector'''\n",
    "        return self.observation_vector\n",
    "        \n",
    "    \n",
    "    def obs_encoding(self, obs_vector=None):\n",
    "        '''returns the state codes of a observation vector'''\n",
    "        if obs_vector is not None:\n",
    "            encodings = []\n",
    "            for obs in obs_vector:\n",
    "                for key, value in self.observables.items():\n",
    "                    if obs == value:\n",
    "                        encodings.append(key)\n",
    "                        break\n",
    "            return np.array(encodings)\n",
    "        \n",
    "        else:\n",
    "            obs_vector = self.obs_vector()\n",
    "            encodings = []\n",
    "            for obs in obs_vector:\n",
    "                for key, value in self.observables.items():\n",
    "                    if obs == value:\n",
    "                        encodings.append(key)\n",
    "                        break\n",
    "            return np.array(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data\n",
    "# all the defualt cases of above implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = Observables(n_observations=4)\n",
    "ObservationVector = obs.vector\n",
    "\n",
    "b = B()\n",
    "matrixB = b.matrix\n",
    "\n",
    "a = A()\n",
    "matrixA = a.matrix\n",
    "matrixA\n",
    "\n",
    "pi = PI()\n",
    "vectorPI = pi.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ObservationVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Active Social Networking', 'Passive Social Networking',\n",
       "       'Active Social Networking', 'Passive Social Networking'],\n",
       "      dtype='<U25')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observationVector in terms of ecodings\n",
    "obs.obs_encoding(ObservationVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05, 0.35, 0.2 , 0.2 , 0.2 ],\n",
       "       [0.5 , 0.1 , 0.3 , 0.1 , 0.  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8  , 0.2  ],\n",
       "       [0.001, 0.999]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward algorithm: calculates probability of observing sequence $O_1, O_2, ....., O_t$ and the final state being in the state $q_t = S_i$ i.e. the forward algorithm parameter is:\n",
    "\\begin{align}\n",
    "\\alpha_t(i) = P(O_1, O_2, ...., O_t, q_t = S_i | \\lambda)\n",
    "\\end{align}\n",
    "\n",
    "the matrix $\\alpha$ is calculated recursively using the relation,\n",
    "\\begin{align}\n",
    "\\alpha_{t+1}(j) = \\Big[ \\sum_i^N \\alpha_t(i) a_{ij} \\Big] b_j(O_{t+1})\n",
    "\\end{align}\n",
    "with initial condition: \n",
    "\\begin{align}\n",
    "\\alpha_1 = \\pi_i(i) b_i(O_1),\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(PI, A, B, Observables):\n",
    "    '''returns the alpha matrix using forward algorithm'''\n",
    "    N = len(Observables)\n",
    "    S = PI.shape[0]\n",
    "    \n",
    "    # initializing the alpha matrix \n",
    "    alpha = np.zeros((N, S))\n",
    "    \n",
    "    # base case initialization\n",
    "    for s in range(S):\n",
    "        alpha[0, s] = PI[s] * B[s, Observables[0]]\n",
    "    \n",
    "    # recursive case\n",
    "    for t in range(1, N):\n",
    "        # sum over s2 to make matrix\n",
    "        for s2 in range(S):\n",
    "            # Recursion Relation:  alpha_i(s2) = [sum_s1 alpha_(i-1)(s1) as1s2] b_s2(i)\n",
    "            alpha[t, s2] = sum(alpha[t-1, s1] * A[s1, s2] for s1 in range(S)) * B[s2, Observables[t]]\n",
    "    \n",
    "    alpha = alpha.transpose()\n",
    "    assert alpha.shape == (S, N)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1       , 0.0280525 , 0.0044918 , 0.00126007],\n",
       "       [0.15      , 0.016985  , 0.00677355, 0.00076651]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = forward(vectorPI, matrixA, matrixB, ObservationVector)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization for each time step is given by, \n",
    "\\begin{align}\n",
    "c_t = \\frac{1}{\\sum_j \\alpha_t(j)}\n",
    "\\end{align}\n",
    "then the normalized $\\hat{\\alpha}_t(j)$ at each time step $t$ is given by,\n",
    "\\begin{align}\n",
    "\\hat{\\alpha}_t(j) = c_t \\alpha_t(j)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to calculate the c_t\n",
    "def ct_value(alpha_t):\n",
    "    '''returns the c_t value for each time step t\n",
    "       takes alpha for time step t (a column vector - as an array)\n",
    "       and returns the corresponding c_t\n",
    "    '''\n",
    "    alpha_sum = 0.0\n",
    "    for i in range(len(alpha_t)):\n",
    "        alpha_sum += alpha_t[i]\n",
    "        \n",
    "    # checking if alpha_sum\n",
    "    if alpha_sum == 0.0:\n",
    "        raise ValueError('sum of alpha values zero!')\n",
    "    # c_t\n",
    "    ct = 1.0/alpha_sum\n",
    "    if ct == 0:\n",
    "        raise ValueError('c_t is zero - leads to NaN!') \n",
    "    return ct\n",
    "\n",
    "# normalized forward algorithm\n",
    "def forward_normalized(PI, A, B, Observables):\n",
    "    '''\n",
    "        scaled/normalized forward algorithm\n",
    "            parameters:\n",
    "                Pi : inital probability of states / array\n",
    "                A: transition probability matrix\n",
    "                B: emission probability\n",
    "                Observables: an array of observables\n",
    "            returns:\n",
    "                a scaled alpha matrix: alpha_scaled\n",
    "                clist: list of c_t for t = 1 to len(Observables)\n",
    "    '''\n",
    "    # sizes\n",
    "    N = len(Observables)\n",
    "    S = PI.shape[0]\n",
    "    \n",
    "    # initialize the base case\n",
    "    alpha = np.zeros((N, S))\n",
    "    for s in range(S):\n",
    "        alpha[0, s] = PI[s] * B[s, Observables[0]]\n",
    "    \n",
    "    # scaling parameters, c_t\n",
    "    clist = list()\n",
    "    c_1 = ct_value(alpha[0])\n",
    "    clist.append(c_1)\n",
    "    \n",
    "    # initializing the scaled alpha: alpha_scaled\n",
    "    alpha_scaled = np.zeros((N, S))\n",
    "    for s in range(S):\n",
    "        alpha_scaled[0, s] = c_1 * alpha[0, s]\n",
    "    \n",
    "    for t in range(1, N):\n",
    "        for s in range(S):\n",
    "            alpha[t, s] = sum((alpha_scaled[t-1, i] * A[i, s] * B[s, Observables[t]]) for i in range(S))\n",
    "            \n",
    "        # calculating and saving c_t values  \n",
    "        c_t = ct_value(alpha[t])\n",
    "        clist.append(c_t)\n",
    "        \n",
    "        # updating alpha_scaled matrix\n",
    "        for s in range(S):\n",
    "            alpha_scaled[t][s] = c_t * alpha[t][s]\n",
    "    \n",
    "    assert len(clist) == len(Observables)\n",
    "    alpha_scaled = alpha_scaled.transpose()\n",
    "    return alpha_scaled, np.array(clist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normalized matrix alpha: \n",
      " [[0.4        0.62286983 0.39872675 0.62177115]\n",
      " [0.6        0.37713017 0.60127325 0.37822885]]\n",
      "\n",
      "list of c_t:  [4.         5.55092978 3.99787792 5.55877753]\n"
     ]
    }
   ],
   "source": [
    "noramlized_alpha, clist = forward_normalized(vectorPI, matrixA, matrixB, ObservationVector)\n",
    "print('')\n",
    "print('normalized matrix alpha: \\n', noramlized_alpha)\n",
    "print('')\n",
    "print('list of c_t: ', clist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation_unnormalized:\n",
    "This is simply: $\\alpha = \\sum_j \\alpha_t (j) = [\\alpha_1, \\alpha_2, ......, \\alpha_T]$ i.e. an array of all $\\alpha$'s for each time step summed over all the hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_unnormalized(alpha):\n",
    "    # summing over the hidden states\n",
    "    return np.sum(alpha, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.0450375 , 0.01126535, 0.00202659])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_unnormalized(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation_normalized:\n",
    "\n",
    "$\\log P = - \\sum_t \\log (c_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_normalized(clist):\n",
    "    '''returns the log of probability of a observation sequence\n",
    "    '''\n",
    "    # logP = -sum_t(log(c_t))\n",
    "    logP = -sum([math.log(c) for c in clist])\n",
    "    # returning the normalized probability\n",
    "    # return math.exp(logP)\n",
    "    return logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.201401718499891"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_normalized(clist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward variable,\n",
    "\\begin{align}\n",
    "\\beta_t(i) = P(O_{t+1:T} | q_t = S_i, \\lambda)\n",
    "\\end{align}\n",
    "is the probability of being in state $q_t = S_i$ at time $t$ and observing the sequence $O_{t+1}, O_{t+2}, ......, O_{T}$, and can be recursively calculated as, \n",
    "\n",
    "\\begin{align}\n",
    "\\beta_t (i) = \\sum_{j=1}^N b_j (O_{t+1}) \\beta_{t+1}(j) a_{ij}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(PI, A, B, Observables):\n",
    "    '''returns the beta matrix'''\n",
    "    # sizes\n",
    "    N = len(Observables)\n",
    "    S = len(PI)\n",
    "    \n",
    "    # initializing beta\n",
    "    beta = np.zeros((N, S))\n",
    "    for s in range(S):\n",
    "        beta[N-1][s] = 1.0\n",
    "    \n",
    "    # recursive updates in beta\n",
    "    for t in reversed(range(N-1)):\n",
    "        for s in range(S):\n",
    "            beta[t][s] = sum((A[s, j] * B[j, Observables[t+1]] * beta[t+1, j]) for j in range(S))\n",
    "            \n",
    "    beta = beta.transpose()\n",
    "    assert beta.shape == (S, N)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0157263 , 0.054015  , 0.3       , 1.        ],\n",
       "       [0.00302639, 0.03010492, 0.10025   , 1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = backward(vectorPI, matrixA, matrixB, ObservationVector)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized backward proability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the matrix $\\beta$:\n",
    "\\begin{align}\n",
    "\\hat{\\beta}_{t}(i) = c_t \\beta_t (i), \\text{where:} \\quad  c_t = \\frac{1}{\\sum_j \\alpha_t(j)}\n",
    "\\end{align}\n",
    "\n",
    "Here, we use the same normalization constants $c_t$ obtained from the forward algorithm. Therefore,\n",
    "\\begin{align}\n",
    "\\sum_i \\hat{\\beta_t}(i) \\ne 1.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_normalized(PI, A, B, c, Observables):\n",
    "    '''returns the normalized beta matrix: using ct from forward algorithm'''\n",
    "    N = len(Observables)\n",
    "    S = len(PI)\n",
    "    \n",
    "    beta = np.zeros((N, S))\n",
    "    beta_scaled = np.zeros((N, S))\n",
    "    \n",
    "    for s in range(S):\n",
    "        beta[N-1][s] = 1.0\n",
    "        try:\n",
    "            beta_scaled[N-1][s] = c[N-1] * 1.0\n",
    "        except:\n",
    "            print('Exception in beta_scaled: ', N-1)\n",
    "            \n",
    "    for t in reversed(range(N-1)):\n",
    "        beta_local = {}\n",
    "        for s in range(S):\n",
    "            beta_local[s] = sum((A[s, i] * B[i, Observables[t+1]] * beta_scaled[t+1, i]) for i in range(S))\n",
    "        \n",
    "        for s in range(S):\n",
    "            beta_scaled[t][s] = c[t] * beta_local[s]\n",
    "    \n",
    "    beta_scaled = beta_scaled.transpose()\n",
    "    assert beta_scaled.shape == (S, N)\n",
    "    return beta_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.7599882 , 6.66329338, 6.66699418, 5.55877753],\n",
       "       [1.4933412 , 3.71374521, 2.22788722, 5.55877753]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_beta = backward_normalized(vectorPI, matrixA, matrixB, clist, ObservationVector)\n",
    "normalized_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing by Forward-Backward Algorithm\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "P(q_t = S_i | O_{1:T}, \\lambda) = \\frac{P(O_{1:t}, q_t = S_i, \\lambda) P(O_{t+1:T} | q_t = S_i, \\lambda)}{ \\sum_j P(O_{1:T}| q_t = S_j, \\lambda) P( q_t = S_j| \\lambda)}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\gamma_t(i) = P(q_t = S_i | O_{1:T}, \\lambda)  = \\frac{\\alpha_t(i) \\beta_t(i)}{\\sum_j \\alpha_t(j) \\beta_t(j)}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_proability(alpha, beta, noOfStates, noOfTimeSteps):\n",
    "    '''retunrs the smoothed gamma matrix'''\n",
    "    \n",
    "    # initializing the gamma matrix\n",
    "    alpha = alpha.transpose()\n",
    "    beta = beta.transpose()\n",
    "    gamma = np.zeros((noOfTimeSteps, noOfStates))\n",
    "    \n",
    "    # first fill gamma with alpha * beta\n",
    "    for t in range(noOfTimeSteps):\n",
    "        for s in range(noOfStates):\n",
    "            gamma[t, s] = alpha[t, s] * beta[t, s]\n",
    "    \n",
    "    # print('gamma: ', gamma.transpose())\n",
    "    # normalizing the gamma matrix\n",
    "    gamma_norm = np.zeros((noOfTimeSteps, noOfStates))\n",
    "    for t in range(noOfTimeSteps):\n",
    "        for s in range(noOfStates):\n",
    "            \n",
    "            # normalization: sum in denominator\n",
    "            gamma_sum = sum(gamma[t][j] for j in range(noOfStates))\n",
    "            \n",
    "            # normalzing each element of gamma\n",
    "            gamma_norm[t, s] = gamma[t, s]/gamma_sum\n",
    "    \n",
    "    return gamma_norm.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77599882, 0.74768815, 0.66492999, 0.62177115],\n",
       "       [0.22400118, 0.25231185, 0.33507001, 0.37822885]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_proability(noramlized_alpha, normalized_beta, len(vectorPI), len(ObservationVector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
